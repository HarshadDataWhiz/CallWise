{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "from transformers import WhisperProcessor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperFeatureExtractor\n",
    "import torch\n",
    "from transformers import  pipeline\n",
    "\n",
    "import json\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e9d1cb",
   "metadata": {},
   "source": [
    "## Processed data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "# Path to processed files\n",
    "processed_path = os.path.join(ROOT_FOLDER, \"data\", \"Processed_Files\")\n",
    "\n",
    "total_duration = 0.0\n",
    "file_durations = {}\n",
    "\n",
    "# Loop through all files\n",
    "for fname in os.listdir(processed_path):\n",
    "    fpath = os.path.join(processed_path, fname)\n",
    "    \n",
    "    if os.path.isfile(fpath) and fname.lower().endswith((\".wav\", \".mp3\", \".flac\", \".ogg\")):\n",
    "        try:\n",
    "            duration = librosa.get_duration(filename=fpath)\n",
    "            file_durations[fname] = duration\n",
    "            total_duration += duration\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {fname}, error: {e}\")\n",
    "\n",
    "# Convert to hours\n",
    "total_hours = total_duration / 3600\n",
    "\n",
    "print(f\"✅ Total audio duration: {total_hours:.2f} hours\")\n",
    "print(f\"✅ Number of files: {len(file_durations)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a67854",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bdd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_FOLDER = ''\n",
    "\n",
    "processed_path = os.path.join(ROOT_FOLDER, \"data\", \"Processed_Files\")\n",
    "all_files = [f for f in os.listdir(processed_path) if f != 'Transcript.json']\n",
    "\n",
    "# First split: Train (85%) vs Temp (15%)\n",
    "train_files, temp_files = train_test_split(all_files, test_size=0.15, random_state=42)\n",
    "\n",
    "# Second split: Temp (15%) into Validation (7.5%) and Test (7.5%)\n",
    "val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build DataFrames\n",
    "df_train = pd.DataFrame({\"filename\": train_files, \"split\": \"train\"})\n",
    "df_val   = pd.DataFrame({\"filename\": val_files, \"split\": \"val\"})\n",
    "df_test  = pd.DataFrame({\"filename\": test_files, \"split\": \"test\"})\n",
    "\n",
    "# Combine all\n",
    "df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "# Save CSV in the same folder\n",
    "output_csv = os.path.join(processed_path, \"file_splits.csv\")\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(df[\"split\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106c64cd",
   "metadata": {},
   "source": [
    "## Test Data set copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = ''\n",
    "df_test = pd.read_csv(os.path.join(ROOT_FOLDER, 'data', 'Processed_Files/file_splits.csv'))\n",
    "df_test = df_test[df_test['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ecf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Example: df_test already exists with a 'filename' column (strings like '...wav')\n",
    "# df_test = pd.read_csv('df_test.csv')  # if loading from disk\n",
    "\n",
    "src_dir = Path(os.path.join(ROOT_FOLDER, 'data', 'Processed_Files/'))\n",
    "dst_dir = Path(os.path.join(ROOT_FOLDER, 'data', 'Processed_Files_2/'))\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)  # safe if it already exists\n",
    "\n",
    "missing, copied = [], 0\n",
    "for name in df_test['filename'].astype(str):\n",
    "    src_path = src_dir / name\n",
    "    if src_path.is_file():\n",
    "        # copy2 preserves timestamps/metadata; copies into directory if dst is a dir\n",
    "        shutil.copy2(src_path, dst_dir)  # destination is a directory\n",
    "        copied += 1\n",
    "    else:\n",
    "        missing.append(name)\n",
    "\n",
    "print(f\"Copied {copied} files to {dst_dir}\")\n",
    "if missing:\n",
    "    print(\"Missing in source:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42705b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "879c7524",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CallWise-_7ZTO6Qn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
