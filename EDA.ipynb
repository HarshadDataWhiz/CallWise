{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fb8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\.virtualenvs\\CollectWise-7aTbe7cb\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "from transformers import WhisperProcessor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperFeatureExtractor\n",
    "import torch\n",
    "from transformers import  pipeline\n",
    "\n",
    "\n",
    "import json\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72776ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT_FOLDER = ''\n",
    "# folder_path = os.path.join(ROOT_FOLDER, 'data/Rec/')\n",
    "# audio_files = os.listdir(folder_path)\n",
    "# Transcript_df = pd.read_csv(os.path.join(ROOT_FOLDER, 'data/ground_truth_gp4_zero_shot.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6daa457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ed1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c953ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n"
     ]
    }
   ],
   "source": [
    "vanilla_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=8,\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11669aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON file\n",
    "ROOT_FOLDER = '.'\n",
    "with open(os.path.join(ROOT_FOLDER, 'data/Processed_Files', \"Transcript.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    transcript_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d27a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted transcript:  Hello, good morning sir, I am speaking with Mrs. Idhan Jain. Sir, this is a Kang Shah calling from one card on the recorded line. I am speaking with Mrs. Idhan Jain. Yeah, thanks for confirming, sir. This call is regarding your latest statement updates of Federal Bank One Credit Card. As you can see, your statement is generated on November 20 and for the same due date was December 7. And you have made a payment of your 10,000 rupees. Thank you so much for the payment sir and I'll request you to make the payment of remaining amount you as early as possible. Hello. So this is a confirmation call about your payment that we have received your confirmation call that we have received your payment. This call is regarding that no issues. Thank you so much.\n"
     ]
    }
   ],
   "source": [
    "# --- File path ---\n",
    "file = '20241208090446_9873656524.mp3_lc.wav'\n",
    "audio_file_path = os.path.join(ROOT_FOLDER, 'data/Processed_Files/', file)\n",
    "\n",
    "# --- Transcription ---\n",
    "prediction = vanilla_pipe(audio_file_path)\n",
    "print(\"Predicted transcript:\", prediction[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f275f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: hello good morning sir am i speaking with mister siddhaant jain sir this is akanksha calling from one card on a recorded line am i speaking with mister siddhaant jain yeah thanks for confirming sir this call is regarding your latest statement updates of federal bank one credit card as i can see your statement is generated on november twenty and for the same due date was december seven and you have made a payment of your ten thousand rupees thank you so much for the payment sir and i request you to make the payment of remaining amount due as early as possible hello sir this is a confirmation call about your payment that we have received your sir this is confirmation call that we have received your payment this call is regarding that okay sir no issues thank you so much\n",
      "WER: 0.3776\n"
     ]
    }
   ],
   "source": [
    "# --- Ground truth transcript ---\n",
    "ground_truth = transcript_json[file]\n",
    "print(\"Ground truth:\", ground_truth)\n",
    "\n",
    "# --- Load WER metric ---\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "# --- Compute WER ---\n",
    "wer_score = wer_metric.compute(\n",
    "    predictions=[prediction[\"text\"]],\n",
    "    references=[ground_truth]\n",
    ")\n",
    "print(f\"WER: {wer_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56226a6",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d994089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "processed_path = os.path.join(ROOT_FOLDER, \"data\", \"Processed_Files\")\n",
    "all_files = [f for f in os.listdir(processed_path) if f != 'Transcript.json' ]\n",
    "\n",
    "train_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = pd.DataFrame({\"filename\": train_files, \"split\": \"train\"})\n",
    "df_test = pd.DataFrame({\"filename\": test_files, \"split\": \"test\"})\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "# Save CSV in the same folder\n",
    "output_csv = os.path.join(processed_path, \"file_splits.csv\")\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9a3a8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1626, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c64f221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_10216\\2283642796.py:16: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
      "\tThis alias will be removed in version 1.0.\n",
      "  duration = librosa.get_duration(filename=fpath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total audio duration: 14.46 hours\n",
      "✅ Number of files: 1626\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "# Path to processed files\n",
    "processed_path = os.path.join(ROOT_FOLDER, \"data\", \"Processed_Files\")\n",
    "\n",
    "total_duration = 0.0\n",
    "file_durations = {}\n",
    "\n",
    "# Loop through all files\n",
    "for fname in os.listdir(processed_path):\n",
    "    fpath = os.path.join(processed_path, fname)\n",
    "    \n",
    "    if os.path.isfile(fpath) and fname.lower().endswith((\".wav\", \".mp3\", \".flac\", \".ogg\")):\n",
    "        try:\n",
    "            duration = librosa.get_duration(filename=fpath)\n",
    "            file_durations[fname] = duration\n",
    "            total_duration += duration\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {fname}, error: {e}\")\n",
    "\n",
    "# Convert to hours\n",
    "total_hours = total_duration / 3600\n",
    "\n",
    "print(f\"✅ Total audio duration: {total_hours:.2f} hours\")\n",
    "print(f\"✅ Number of files: {len(file_durations)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808544e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85df13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ecf63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc66d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42705b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "879c7524",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CollectWise-7aTbe7cb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
