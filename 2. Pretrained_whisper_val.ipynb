{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\.virtualenvs\\CollectWise-7aTbe7cb\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "from transformers import WhisperProcessor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperFeatureExtractor\n",
    "import torch\n",
    "from transformers import  pipeline\n",
    "\n",
    "import json\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e9d1cb",
   "metadata": {},
   "source": [
    "## Processed data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cff59a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_7432\\2283642796.py:16: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
      "\tThis alias will be removed in version 1.0.\n",
      "  duration = librosa.get_duration(filename=fpath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total audio duration: 14.46 hours\n",
      "✅ Number of files: 1626\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "# Path to processed files\n",
    "processed_path = os.path.join(ROOT_FOLDER, \"data\", \"Processed_Files\")\n",
    "\n",
    "total_duration = 0.0\n",
    "file_durations = {}\n",
    "\n",
    "# Loop through all files\n",
    "for fname in os.listdir(processed_path):\n",
    "    fpath = os.path.join(processed_path, fname)\n",
    "    \n",
    "    if os.path.isfile(fpath) and fname.lower().endswith((\".wav\", \".mp3\", \".flac\", \".ogg\")):\n",
    "        try:\n",
    "            duration = librosa.get_duration(filename=fpath)\n",
    "            file_durations[fname] = duration\n",
    "            total_duration += duration\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {fname}, error: {e}\")\n",
    "\n",
    "# Convert to hours\n",
    "total_hours = total_duration / 3600\n",
    "\n",
    "print(f\"✅ Total audio duration: {total_hours:.2f} hours\")\n",
    "print(f\"✅ Number of files: {len(file_durations)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a67854",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2bdd11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    0.849416\n",
      "test     0.075599\n",
      "val      0.074985\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_FOLDER = ''\n",
    "\n",
    "processed_path = os.path.join(ROOT_FOLDER, \"data\", \"Processed_Files\")\n",
    "all_files = [f for f in os.listdir(processed_path) if f != 'Transcript.json']\n",
    "\n",
    "# First split: Train (85%) vs Temp (15%)\n",
    "train_files, temp_files = train_test_split(all_files, test_size=0.15, random_state=42)\n",
    "\n",
    "# Second split: Temp (15%) into Validation (7.5%) and Test (7.5%)\n",
    "val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build DataFrames\n",
    "df_train = pd.DataFrame({\"filename\": train_files, \"split\": \"train\"})\n",
    "df_val   = pd.DataFrame({\"filename\": val_files, \"split\": \"val\"})\n",
    "df_test  = pd.DataFrame({\"filename\": test_files, \"split\": \"test\"})\n",
    "\n",
    "# Combine all\n",
    "df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "# Save CSV in the same folder\n",
    "output_csv = os.path.join(processed_path, \"file_splits.csv\")\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(df[\"split\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884deabc",
   "metadata": {},
   "source": [
    "## Pretrained whisper-small Test validation res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\")\n",
    "\n",
    "# Read JSON file\n",
    "ROOT_FOLDER = '.'\n",
    "with open(os.path.join(ROOT_FOLDER, 'data/Processed_Files', \"Transcript.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    transcript_json = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b808544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.Validation import validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85df13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    }
   ],
   "source": [
    "file_list = ['20241208090446_9873656524.mp3_lc.wav']\n",
    "res = validation(model , processor, transcript_json, file_list, ROOT_FOLDER = \"data/Processed_Files/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d1ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ecf63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc66d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42705b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "879c7524",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CollectWise-7aTbe7cb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
