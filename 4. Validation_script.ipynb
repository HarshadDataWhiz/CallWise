{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1fb8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "from transformers import WhisperProcessor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperFeatureExtractor\n",
    "import torch\n",
    "from transformers import  pipeline\n",
    "\n",
    "import json\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884deabc",
   "metadata": {},
   "source": [
    "## Pretrained whisper-small Test validation res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\")\n",
    "\n",
    "# Read JSON file\n",
    "ROOT_FOLDER = '.'\n",
    "with open(os.path.join(ROOT_FOLDER, 'data/Processed_Files', \"Transcript.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    transcript_json = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Validation import validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85df13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    }
   ],
   "source": [
    "file_list = ['20241208090446_9873656524.mp3_lc.wav']\n",
    "res = validation(model , processor, transcript_json, file_list, ROOT_FOLDER = \"data/Processed_Files/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2393285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\P2_ASR\\\\CallWise'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c7524",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CallWise-_7ZTO6Qn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
